config:
  learning_rate: 0.2
  noise_std_dev: 0.4
  n_populations: 1000
  n_individuals: 100
  n_timesteps_per_trajectory: 200

  algorithm: "EntES"
  environment: "MOGame"
  environment_index: 1
  model: "FeedForwardNeuralNetwork"
  reward: "mo_death"
  multiple_rewards: "mo_time_score, mo_death, mo_success"
  hidden_layer_activation: "selu"
  output_activation: "softmax"
  output_scale: 1

  n_hidden_layers: 1
  n_nodes_per_layer: 10
  input_size: 1125
  output_size: 5

  from_file: False
  params_file: 'ext/02-21-2018_18-14-54/params/params_0.py'
  save_every: 20

  visualize: True
  visualize_every: 100